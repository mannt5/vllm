Offline Inference Neuron Int8 Quantization
==========================================

Source https://github.com/vllm-project/vllm/blob/main/examples/offline_inference_neuron_int8_quantization.py.

.. literalinclude:: ../../../../examples/offline_inference_neuron_int8_quantization.py
    :language: python
    :linenos:
