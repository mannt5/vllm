nav:
  - Getting Started:
    - getting_started/quickstart.md
    - getting_started/installation
    - Examples:
      - LMCache: getting_started/examples/lmcache
      - getting_started/examples/offline_inference
      - getting_started/examples/online_serving
      - getting_started/examples/other
    - Other:
      - getting_started/*
  - Models:
    - models/supported_models.md
    - models/generative_models.md
    - models/pooling_models.md
    - models/extensions
  - Features:
    - features/compatibility_matrix.md
    - features/*
    - features/quantization
  - Training: training
  - Inference and Serving:
    - serving/offline_inference.md
    - serving/openai_compatible_server.md
    - serving/*
    - serving/integrations
  - Deployment:
    - deployment/*
    - deployment/frameworks
    - deployment/integrations
  - Performance: performance
  - Design Documents:
    - V0: design
    - V1: design/v1
  - Developer Guide:
    - contributing/overview.md
    - glob: contributing/*
      flatten_single_child_sections: true
    - contributing/model
  - API Reference:
    - api/README.md
    - api/vllm/*
  - Community:
    - vLLM Blog: https://blog.vllm.ai
    - community/*

