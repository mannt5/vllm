import torch

hadamard_28=torch.FloatTensor([
    [
        +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, -1, +1, +1, +1, +1, +1, +1,
        +1, +1, +1, +1, +1, +1, +1],
    [
        +1, +1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, +1, -1, +1, -1, +1, +1, -1, -1,
        -1, -1, +1, +1, -1, +1
    ],
    [
        +1, +1, +1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, +1, -1, +1, -1, +1, +1,
        -1, -1, -1, -1, +1, +1, -1
    ],
    [
        +1, -1, +1, +1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, +1, -1, +1, -1, +1, -1, +1,
        +1, -1, -1, -1, -1, +1, +1
    ],
    [
        +1, +1, -1, +1, +1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, +1, -1, +1, -1, +1, -1,
        +1, +1, -1, -1, -1, -1, +1
    ],
    [
        +1, +1, +1, -1, +1, +1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, +1, -1, +1, -1, +1,
        -1, +1, +1, -1, -1, -1, -1
    ],
    [
        +1, -1, +1, +1, -1, +1, +1, +1, -1, +1, +1, -1, -1, -1, +1, -1, +1, +1, -1, +1, -1,
        +1, -1, +1, +1, -1, -1, -1
    ],
    [
        +1, -1, -1, +1, +1, -1, +1, +1, +1, -1, +1, +1, -1, -1, +1, -1, -1, +1, +1, -1, +1,
        -1, +1, -1, +1, +1, -1, -1
    ],
    [
        +1, -1, -1, -1, +1, +1, -1, +1, +1, +1, -1, +1, +1, -1, +1, -1, -1, -1, +1, +1, -1,
        +1, -1, +1, -1, +1, +1, -1
    ],
    [
        +1, -1, -1, -1, -1, +1, +1, -1, +1, +1, +1, -1, +1, +1, +1, -1, -1, -1, -1, +1, +1,
        -1, +1, -1, +1, -1, +1, +1
    ],
    [
        +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, +1, +1, -1, +1, +1, +1, -1, -1, -1, -1, +1,
        +1, -1, +1, -1, +1, -1, +1
    ],
    [
        +1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, +1, +1, -1, +1, +1, +1, -1, -1, -1, -1,
        +1, +1, -1, +1, -1, +1, -1
    ],
    [
        +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, +1, +1, +1, -1, +1, +1, -1, -1, -1,
        -1, +1, +1, -1, +1, -1, +1
    ],
    [
        +1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, +1, +1, +1, -1, +1, +1, -1, -1,
        -1, -1, +1, +1, -1, +1, -1
    ],
    [
        -1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, -1, -1, -1, -1, -1, -1, -1,
        -1, -1, -1, -1, -1, -1, -1
    ],
    [
        +1, -1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, -1, -1, -1, +1, -1, -1, +1,
        +1, +1, +1, -1, -1, +1, -1
    ],
    [
        +1, +1, -1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, -1, -1, -1, -1, -1, +1, -1, -1,
        +1, +1, +1, +1, -1, -1, +1
    ],
    [
        +1, -1, +1, -1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, -1, -1, -1, +1, -1,
        -1, +1, +1, +1, +1, -1, -1
    ],
    [
        +1, +1, -1, +1, -1, +1, -1, +1, +1, -1, -1, -1, -1, +1, -1, -1, +1, -1, -1, -1, +1,
        -1, -1, +1, +1, +1, +1, -1
    ],
    [
        +1, +1, +1, -1, +1, -1, +1, -1, +1, +1, -1, -1, -1, -1, -1, -1, -1, +1, -1, -1, -1,
        +1, -1, -1, +1, +1, +1, +1
    ],
    [
        +1, -1, +1, +1, -1, +1, -1, +1, -1, +1, +1, -1, -1, -1, -1, +1, -1, -1, +1, -1, -1,
        -1, +1, -1, -1, +1, +1, +1
    ],
    [
        +1, -1, -1, +1, +1, -1, +1, -1, +1, -1, +1, +1, -1, -1, -1, +1, +1, -1, -1, +1, -1,
        -1, -1, +1, -1, -1, +1, +1
    ],
    [
        +1, -1, -1, -1, +1, +1, -1, +1, -1, +1, -1, +1, +1, -1, -1, +1, +1, +1, -1, -1, +1,
        -1, -1, -1, +1, -1, -1, +1
    ],
    [
        +1, -1, -1, -1, -1, +1, +1, -1, +1, -1, +1, -1, +1, +1, -1, +1, +1, +1, +1, -1, -1,
        +1, -1, -1, -1, +1, -1, -1
    ],
    [
        +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, -1, +1, -1, +1, -1, -1, +1, +1, +1, +1, -1,
        -1, +1, -1, -1, -1, +1, -1
    ],
    [
        +1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, -1, +1, -1, -1, -1, -1, +1, +1, +1, +1,
        -1, -1, +1, -1, -1, -1, +1
    ],
    [
        +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, -1, +1, -1, +1, -1, -1, +1, +1, +1,
        +1, -1, -1, +1, -1, -1, -1
    ],
    [
        +1, +1, -1, +1, +1, -1, -1, -1, -1, +1, +1, -1, +1, -1, -1, -1, +1, -1, -1, +1, +1,
        +1, +1, -1, -1, +1, -1, -1
    ]]).to("cuda:0").bfloat16()

import fast_hadamard_transform
scale=1.0/torch.tensor(512*28).sqrt()

def R4_Function_Llama_3_8B(x: torch.Tensor):
    og_shape=x.shape
    x = fast_hadamard_transform.fast_hadamard_transform(x.view(-1,512),scale)
    x = hadamard_28.view(1, 28, 28) @ x.view(-1,28,512)
    return x.view(og_shape)

"""
def R4_Function_Llama_3_8B(x: torch.Tensor):
    return fast_hadamard_transform.fast_hadamard_transform_28N(x,scale)
"""